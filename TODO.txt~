
Data 29
- 
- MongoDB
-exercicios Francis
-Pagar pai da paul - ok
Itau bco 341 / 3241 / 3421
Agencia : 6429
Cc 11.428-0

BRADESCO:bco 237
ag 3430  
Cc:0001604-7


Nome: Nacib rishala abu Asseff
Cpf: "26227148-29"

Data 30

- MongoDB
	testes python
	testes bash
	testes javascript
	
-exercicios Francis
	ok fork
	ok pthreads
	ok 

 gcc -c foo.c
 gcc foo.c -o foo
 

Compilando:
 gcc -c source.c
 gcc -o source.o

Makefiles - ok

Direto:
 gcc -o programa source1.c source2.c
 .programa
 
Data 2 Setembro
	- see email:
	Francois
		- javascript mongodb - ok
			fazer o exemplo de bash em js
		- mutual exclusion: entender, aplicar em um exemplo com python, fazer um exemplo

		- analisar com trace compare ambos os testes
		- achar mais problemas
		- implementar outro problema: reading from disk with php
		
	- fork x pthreads x pth
		portable threads

	- paraver
	- reading about trace correlation - master thesis
	- frances
Data 3 de Setembro
		- Finalizacao de exercicios trace compare	
		- strace
Data 4 de Setembro
	- regular meeting - progess meeting
	- Reading again the article of francois
	
	- reading about trace correlation, since it is pointed "Comparison of system call traces recorded on different operating systems has been used to detect intrusions. Since some variations are inherent to the use of different operating systems, the authors transform low-level events into higher-level concepts to allow a meaningful comparison. Their algorithm computes a correlation score for two traces, but doesnt show individual differences. Also, it doesnt take timing into account"
	- Leitura: State History Tree: an Incremental disk-based structure for very large interval data	
	- Leitura Thesis of Trace Correlation
	- 
Data 5 de Setembro
	- Negociar com banco - ok
	- Final de Leitura - Trace Correlation
	- Ler Performance Debugging in the Large via Mining millions of Stack Traces
	- Summary of Papers - ok doing
		
		TraceDiff
			Gosma tool
			It is a visualization and mining tool for traces, which provides according to the authors: scalabilitym robustness and ease to use. This can show different metrics but the main one is to show strong and weak similarity bettwen function calls
						
		IntroPerf
		
		perf to call stack
		
		libundwind: tests with perf
			
	- http://www.tele-task.de/archive/series/overview/883
	- Fazer backup docs - ok
	- Completar um pouco do PhD escrito - ok
	- 
	- Lttng-simple understanding
	
	
Data 6 de Setembro:
	- chegar cedo!! - ok
	- Ler: Article 1:  Efficient Methods for trace analysis parallelization
		
	- 9 mostrar trampos pro Francis - cheguei 9h30
	
	- Do more tests with TraceCompare		
	- Do tests with perf and libunwind
	- Trace Compass example of State History Tree
		> generate them with trace compass

	- re-do the implementation with python and CFT
		
	- Apresentacao Chefe - tenso
		Muito legal, muito legal mesmo =D
			Sai com uma pergunta: 
			Quais partes de um programa sao as mais rapidas caso executado duas vezes? E caso executado n vezes, com pequenas mudancas?

				GNU super optimizer
				achar os hot spots que gastem mais/menos tempo ->
				What is the 
				Find correlation patter bettween the runs?
				Keep track of the samples so you can track the fast
				fazer as alteracoes em paralelo para ser mais rapido

	- Linux trainning
	- Libunwind program

Prototipo>>>>>	Comparar programas de pontos em pontos
	SuperOtimization	
			What is it?
			Superoptimization is the task of finding the optimal code sequence for a single, loop-free sequence of instructions. While garden-variety compiler optimizations really just improve 				code (real-world compilers generally cannot produce genuinely optimal code), a superoptimizer's goal is to find the optimal sequence.
					
			as used superoptimization to automatically generate general-purpose peephole optimizers.
			
-saturday

Python bidings with babeltrace

Profiler visualization:
	gprof2dot
	gprof test | gprof2dot.py > foo.dot


- libunwind x history tree x calling context tree
- stacks builder x state history in tibeecompare

monday 09/11
	- state history tree x calling context
	TODO in Francois work:
		- Declarative language used for trace analysis
		- Analyze performance regressions: with by allowing the user to provide a file, mapping old function names to new names
		- Dealing with code refactoring, 
				> Static analysis techniques exist to identify cloned syntactic blocks between multiple source files
				> 
				comparison between traces recorded on different versions of the same program,
		- avec le mode flight recorder de LTTng
		- allow userspace processes to associate metrics with the current execution (e.g. number of returned results)
		- handle programs written in a dynamic language and JIT compiled.
		
		- Il serait particulièrement intéressant de savoir comment se comporte notre solution dans des environnements
		virtualisés tels que OpenStack ou Amazon Web Services.
	
	Limitation
		Our userspace tracing library can only capture the stack for ELF binaries
		To handle out of the box the specificities of each application

	-Implementation of Learning Base Correlation
		http://www.cs.cornell.edu/people/tj/publications/finley_joachims_05a.pdf
		http://www.cs.sfu.ca/CourseCentral/741/jpei/readings/baya98.pdf
		Implementation of SVM in python with 	
	
	- Francais - ok
tuesday 10/11
	
	Defining the model to apply compare in svm
	Writing the code	

	- French
	- TCF Quebec
	- Apply for CSQ
	- Federal application
	
wednesday 11/11
	- Meta: Ser o homem que a mama queria
		rezar 2 vezes ao dia - ok
		
	- Reuniao = cancelada
	- Delphi - adiado
	- Pegar um livro de compiladores - ok
	- mapa astral
		ascendente em gemeos? lol! 
	- exercicios - ok
	- 4.1 - fazendo
	- decision tree
		ver tutoriais


thursday 12/11
	- learn french
	new email:
		- francisco_melo_jr@outlook.com
			
friday 13/11
	- todo:
		multilock
		spinlock

		touch - linux command
		make clean
		make

		void *semrelay_worker(void *ptr) {
		unsigned long i, j;
		struct experiment *exp = ptr;

		for (i = 0; i < exp->outer; i++) {
			// TODO: wait
			sem_wait(exp->lock);
			for (j = 0; j < exp->inner; j++) {
				unsigned long idx = (i * exp->inner) + j;
				statistics_add_sample(exp->data, (double) idx);
			}
			// TODO: post
			sem_post(exp->lock);
		}
		return NULL;
	}

	void semrelay_init(struct experiment *exp) {
		exp->data = make_statistics();
		// TODO: allocate a table of semaphores in exp->lock
		// TODO: initialize the semaphores

		exp->lock = malloc(sizeof(sem_t));
		sem_init(exp->lock,0,1); //init
	}

	void semrelay_done(struct experiment *exp) {
		statistics_copy(exp->stats, exp->data);
		free(exp->data);
		// TODO: cleanup
		free(exp->lock);

	}

	Friday = Beatles!
	traces

Monday
	todo
		implementar semrelay ok
		implementar interblocage ok
		mandar 760 doletas
		
Tuesday
	Falar com Naser
		implementar lexique - almost
		implementar virtual memory - doing
		Ligar Luzia - *--*
		Cartao de credito MasterCard - ok 
		resolver treta Marcelo - ok
		pegar dinheiro Hani - 15o doletas
		mercado
Wedneday
		meeting - it was good, keep going, lets see the results
		> the user should choose the 
		> the number of groups is abstracted from the machile learn stuff		
	
Thursdays
	11	Abrir conta Scotia Banque
		Renegociar cartao de credito
		French lessons		
		Home: 45.506752,-73.6236724

Questions for Francis
	1- lexique (atv 5)
	2- pagedump (atv 6)
		write( out, a, sizeof(a)) == -1)	
	3- python buildings (atv 7)

	AttributeError: 'dict' object has no attribute 'has_key'
	ldconfig
		ImportError: No module named 'babeltrace.reader'; 'babeltrace' is not a package
		
		Install babeltrace with python bindings
		First: Remove 
			sudo apt-get autoremove babeltrace
			sudo apt-get autoremove	python3-babeltrace
			sudo apt-get remove babeltrace
		Then:
			export PYTHON="python3"
			export PYTHON_CONFIG="/usr/bin/python3-config"
			./configure --enable-python-bindings
			make
			make install
	

	4- segfault (atv 8)
		how to compute the 
			
		1 Signal handler:		
			a
	 	2 break
	           for(;;)			
	5- randaddr (atv 9) 
		didnt get yet the personality

	Todo
		Pay stuff itau - ok
		Assignment 2
		Draft Research proposal
		Finish Francis trainning
	
		Trace Correlation as a form of high level analysis and automated anomaly detection is an important and promising area
		Camila Silvestre Nunes
		LCI sem imposto de renda
Friday
		finalizar tarefas
		french classes
		enviar assigment 
		
		6		
		7
			python stuff
		8
			while(1)
				acessing the memory
		9

Saturday
		French
		Francis stuff	
		Demonstracao svm
			Organizing data
			Labeling the data

Monday - 23
	Class at 9h30
	Finishing SVM 	

Tuesday - 24
	Taking the results and coming with some data
	- ok
Wednesday - 25
	
	Do the assigment
	
	Research:	
		changing the dimensions

	Training:
		- lexique
		- 
	Outros:
		- ligar yuri
		- falar com carlos
		- cartao
			- nao legal
	Study french
	
Thursday - 26
	Send the stuff - wake up early and do it at my house worked almost
	do the 3d plot
	do svm with 3 dimensions
	study german
	email 
	mercado
	ate at the coffeteria
	finish assigment 6
	question about assigment 7
	
Friday
	at 15h
		present work for Naser
	do assigment 7
		python problem
			solution:

	Conection ssh:	
	ssh isdema@l4712-01.info.polymtl.ca -X
	12saisoJ

	Write verbs in french -ok
	French inscription	
	
Samadi	

Dimanchi
	Tenchi muyo
		tenchi universe
		tenchi movie forever
		tenchi wiki

Mon
	Example for Naser
	Talk with Hani
	
Tuesday
	PR
		24 months of authorized full-time live-in employment

	Citizen:
		Have lived in Canada as a PR for at least 4 years out of the 6 years (1,460 days) before you apply.	

	Total: 6 ans (4 as pr and 2 as work permit)












#Panda:
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.pyplot import *

from collections import Counter

#CSV:
import csv

#array to list:
import numpy as np

#Json:
import json
from pprint import pprint

with open('test3.json') as data_file:    
    data = json.load(data_file)

#pprint(data)
#for each1 in data['executions']:
#    for each2 in each1:
#        print each2
##This function takes a character as argument and return a list:
##for each json info it creates a list
##{u'a': 28,u'b': 1446538515159875,u'h': 28,u'samples': {u'84': 28, u'85': 28, u'86': 28}}
##gives you: lista a: [28], list b = [1446538515159875], 
def do_lists(arg):
    "Function Do lists:"
    x = 0
    max = len(data['executions'])
    ##Couting a:
    a_list = []
    #shows:
    while x < max:
        #print data['executions'][x]['a'] #line 1
        a_list.append(data['executions'][x]['a'])#put in a array:
        x += 1
        
    #print(len(a_list))
    #print(a_list)

    ##Couting b:
    x = 0
    b_list = []
    #shows:
    while x < max:
        #print data['executions'][x]['b'] #line 1
        b_list.append(data['executions'][x]['b'])#put in a array:
        x += 1
        
    #print(len(b_list))
    #print(b_list)

    ##Couting h:
    x = 0
    h_list = []
    #shows:
    while x < max:
        #print data['executions'][x]['a'] #line 1
        try:
            val = data['executions'][x]['h']
            if val is not None:#put in a array:
                h_list.append(val)
        except:
            pass
        x += 1
        
    #print(len(h_list))
    #print(h_list)

    ##Couting f:
    x = 0
    f_list = []
    #shows:
    while x < max:
        #print data['executions'][x]['a'] #line 1
        try:
            val = data['executions'][x]['f']
            if val is not None:#put in a array:
                f_list.append(val)
        except:
            pass
        x += 1
    #print(f_list)        
    #print(len(f_list))

    if(arg is 'a'):
        return a_list
    
    if(arg is 'b'):
        return b_list
    
    if(arg is 'h'):
        return h_list
    
    if(arg is 'f'):
        return f_list

       
    return arg

    #print len(item_dict['executions'][1]['a'])

##This function takes a list as argument and plots:
def do_graph(a):
    "Function Do lists:"
    #a = ['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'd', 'e', 'e', 'e', 'e', 'e']
    counts = Counter(a)
    df = pd.DataFrame.from_dict(counts, orient='index')
    df.plot(kind='bar')
    plt.show()
    
##This function takes a list as argument and returns a histogram:
def do_histogram(a):
    "Function Do histogram:"
    #a = ['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'd', 'e', 'e', 'e', 'e', 'e']
    counts = Counter(a)
    #df = pd.DataFrame.from_dict(counts, orient='index')
    #df.plot(kind='bar')
    #plt.show()
    print(counts)
    return counts

#this function takes a histogram and creates a csv file:
def create_csf(mylist):
    with open("test3x.csv", "wb") as f:
        writer = csv.writer(f)
        writer.writeheader("Value","Quantity")
        writer.writerows(mylist)

#this function creates a array:
def create_array(mylist):
    p = []
    for letter in mylist:
        a = [letter, mylist[letter]]
        p.append(a)
    print p
    return p #p is an array of arrays: [[4,7],[85,1] ...]

lista = do_lists('a')
print(len(lista))

#do graph:
#do_graph(lista)
histogram = do_histogram(lista)

array = create_array(histogram)
print(array)

create_csf(array)








































				
Monday
Tuesday
Wednesday
Thursday
Friday		

		

			
		
	
